{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "import konlpy.tag \n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import itertools\n",
    "import operator\n",
    "import numpy as np\n",
    "import MySQLdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = MySQLdb.connect(\n",
    "    \"127.0.0.1\",\n",
    "    \"root\",\n",
    "    \"****\",\n",
    "    \"****\",\n",
    "    charset='utf8',\n",
    ")\n",
    "\n",
    "SQL_QUERY = \"\"\"\n",
    "    SELECT content\n",
    "    FROM reply\n",
    "    WHERE member_group_seq = 2481058\n",
    "\"\"\"\n",
    "\n",
    "comment_df = pd.read_sql(SQL_QUERY, db)\n",
    "len(comment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def shuffle_df(df):\n",
    "    return df.iloc[np.random.permutation(len(df))].reset_index(drop=True) \n",
    "\n",
    "def get_datas(date):\n",
    "    article_df = pd.read_csv(\"./news/\" + date + \".csv\")\n",
    "    article_df = shuffle_df(article_df)\n",
    "    comment_df = pd.read_csv(\"./comment/comment1.csv\")\n",
    "    return article_df, comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_document_morpheme(texts):\n",
    "    \"\"\"make documents list after morphological\"\"\"\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    komoran = konlpy.tag.Komoran()\n",
    "    \n",
    "    for text in texts:\n",
    "        obj = line2obj(komoran.pos(text, flatten=False))\n",
    "        documents.append(obj)\n",
    "        \n",
    "    return documents\n",
    "\n",
    "def line2obj(lines):\n",
    "    \"\"\" make keywords dictionary include only (NNP, NNG)\"\"\"\n",
    "    \n",
    "    obj = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        for keyword in line:\n",
    "            if len(keyword[0]) > 1 and ( keyword[1] == \"NNP\" or keyword[1] == \"NNG\" ) :\n",
    "                key = keyword[0]\n",
    "                if key in obj:\n",
    "                    obj[key] += 1\n",
    "                else:\n",
    "                    obj[key] = 1\n",
    "                    \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_text_documents(documents):\n",
    "    \n",
    "    text_documents = []\n",
    "    \n",
    "    for document in documents:\n",
    "        \n",
    "        text_words = []\n",
    "        \n",
    "        for word, count in document.items():\n",
    "            text_words.extend([word] * count)\n",
    "            \n",
    "        text_document = \" \".join(text_words)\n",
    "        text_documents.append(text_document)\n",
    "        \n",
    "    return text_documents        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_euc_dist(v1, v2):\n",
    "    delta = v1 - v2\n",
    "    dist = sp.linalg.norm(delta.toarray())\n",
    "    return dist\n",
    "\n",
    "def get_euc_dists(vectorized, num_docs):\n",
    "    \n",
    "    dists = []\n",
    "    \n",
    "    for idx in range(num_docs-1):\n",
    "        dist = calc_euc_dist(vectorized.getrow(num_docs-1), vectorized.getrow(idx))\n",
    "        dists.append((num_docs-1, idx, dist))\n",
    "        \n",
    "    return dists\n",
    "\n",
    "def sort_dists(dists):\n",
    "    result_list = []\n",
    "    for i, j, dist in sorted(dists, key=operator.itemgetter(2)):\n",
    "        result_list.append((i, j, dist))\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1873, 118)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df, comment_df = get_datas(\"2016-07-07\")\n",
    "len(article_df), len(comment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comment_str = comment_df[\"content\"][:].str.cat(sep=' ')\n",
    "article_series = article_df[\"content\"][:100]\n",
    "article_series = article_series.append(pd.Series([comment_str])).reset_index(drop=True)\n",
    "article_documents = make_document_morpheme(article_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_articles = gen_text_documents(article_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of input documents : 101\n",
      "the number of words : 4920\n",
      "feature word list : ['10월', '11월', '11일', '12월', '14일'] ...\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "# vectorizer = CountVectorizer(min_df=5)\n",
    "vectorizer = TfidfVectorizer()\n",
    "# vectorizer = HashingVectorizer()\n",
    "\n",
    "vectorized = vectorizer.fit_transform(gen_articles)\n",
    "num_docs, num_features =  vectorized.shape\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "print(\"the number of input documents : {}\".format(num_docs))\n",
    "print(\"the number of words : {}\".format(num_features))\n",
    "print(\"feature word list : {} ...\".format(feature_names[:5]))\n",
    "result_df = pd.DataFrame(vectorized.toarray(), columns=feature_names)\n",
    "print(len(result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(100, 85, 1.3112674561686739),\n",
       " (100, 4, 1.3569742716238888),\n",
       " (100, 87, 1.3607389715291252),\n",
       " (100, 3, 1.3631734414992085),\n",
       " (100, 20, 1.3684475790269628),\n",
       " (100, 47, 1.3686002000867816),\n",
       " (100, 61, 1.3739372918104225),\n",
       " (100, 30, 1.3780200714031974),\n",
       " (100, 80, 1.3787860342228229),\n",
       " (100, 69, 1.3794866600373896)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = get_euc_dists(vectorized, num_docs)\n",
    "result = sort_dists(dists)\n",
    "result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comment, rank_idx, distance = zip(*result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "선거구 없으니까..\n",
      "국민들이 더 좋아한다 ^^*\n",
      "\n",
      "국가재정도 든든해지고..\n",
      "코메디... 이번총선은...  우리국민들이..\n",
      "양당기득권패권주의  심판..\n",
      "\n",
      "정말 한심하다...\n",
      "선거구 \n"
     ]
    }
   ],
   "source": [
    "# comment\n",
    "print(article_series[comment[0]][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[동아일보]여권의 차기 대선 주자로 거론되는 남경필 경기도지사(사진)가 6일 ‘보수의 심장’인 대구를 찾아 특강과 지역 언론 인터뷰 등을 하며 보폭을 넓히고 있다.  남 지사는 이날 대구 경북대에서 열린 토크콘서트 강연에서 “민주화 이후 대구경북(TK)에서 3명의 대통령을 배출했지만 그 혜택이 국민에게 오지 않고 일부 정치인에게만 돌아갔다”고 지적했다. 이어 “해법을 내놓지 못하면 대한민국의 미래는 없다. TK가 대한민국 변화의 중심이 돼야 한다”며 지역 민심 끌어안기에 나섰다.  남 지사는 변화의 방향으로 ‘혁신과 통합의 새 리더십’을 강조했다. 그는 “이번 총선 때 무소속으로 출마한 유승민 의원과 더불어민주당 김부겸 의원이 당선되며 대구에서 희망을 봤다”며 “TK발 혁신과 통합이 시작됐고 여기서 불을 끄지 말고 변화를 만들어 보자”고 했다. 영남지역을 기반으로 기존 새누리당 주류 세력과 차별화하려는 의도로 보인다.  남 지사는 2017년 대선 출마와 관련해 최근 한 라디오 방송에서 “내년까지 고민하고 입장을 밝힐 예정”이라고 말했다. 이날도 “(내년 대선과) 무관하다면 거짓말이다. 그런데 목표는 (일단) 경기도 리빌딩”이라고 답했다.  강연 후 이어진 질의응답에선 자신을 둘러싼 평가에 적극 방어하는 모습을 보였다. 부친인 남평우 전 의원의 지역구를 물려받은 뒤 ‘비단길만 걸었다’는 지적에는 “한 번도 주류를 해본 적이 없다”며 “야당 10년을 했고, 여당이 된 뒤 지금도 비박(비박근혜)이라는 꼬리표가 붙어 있다”고 설명했다. 홍수영 기자 gaea@donga.com▶ 동아일보 단독 / 동아일보 공식 페이스북▶ 매일 업데이트 되는 무료인기만화, 빅툰ⓒ 동아일보 & donga.com, 무단 전재 및 재배포 금지\n"
     ]
    }
   ],
   "source": [
    "# recommend article\n",
    "idx = rank_idx[0]\n",
    "print(article_series[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
